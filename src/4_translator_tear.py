#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TEaRç¿»è¯‘è„šæœ¬ (Agent 2: Translation & Refinement Agent)
åŠŸèƒ½ï¼šå®ç°ç¿»è¯‘-è¯„ä¼°-æ¶¦è‰²çš„å¾ªç¯æµç¨‹ï¼ŒåŒ…å«å›è¯‘éªŒè¯
"""

import json
import os
import time
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser

# --- ğŸ“ é…ç½®è·¯å¾„ ---
INPUT_FILE = "../data/processed/è¯¡ç§˜ä¹‹ä¸»_final.jsonl"
GLOSSARY_FILE = "../data/glossary/project_knowledge_base.json"
OUTPUT_FILE = "../data/output/è¯¡ç§˜ä¹‹ä¸»_tear_result.jsonl"

# --- ğŸ¤– åˆå§‹åŒ–æ¨¡å‹ (DeepSeek) ---
def init_llm(model_name: str = "deepseek-chat", temperature: float = 0.3):
    """
    åˆå§‹åŒ–LLMæ¨¡å‹
    
    Args:
        model_name: æ¨¡å‹åç§°
        temperature: æ¸©åº¦å‚æ•°
        
    Returns:
        åˆå§‹åŒ–åçš„LLMå®ä¾‹
    """
    return ChatOpenAI(
        model="deepseek-ai/DeepSeek-R1-0528-Qwen3-8B",
        api_key="sk-cautwxmuhdpxhtuilctlfpecaoxpzhagpzfzmkdxgrywjpum", 
        base_url="https://api.siliconflow.cn/v1/",
        temperature=0.1 # ç¿»è¯‘ä»»åŠ¡éœ€è¦ä½æ¸©åº¦ï¼Œä¿æŒä¸¥è°¨
    )

# --- ğŸ“– è¾…åŠ©å‡½æ•°ï¼šåŠ è½½æœ¯è¯­è¡¨ ---
def load_glossary_context():
    """
    åŠ è½½æœ¯è¯­è¡¨ä¸Šä¸‹æ–‡
    
    Returns:
        æ ¼å¼åŒ–çš„æœ¯è¯­è¡¨æ–‡æœ¬
    """
    if not os.path.exists(GLOSSARY_FILE):
        return "No glossary available."
    
    with open(GLOSSARY_FILE, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # æ ¼å¼åŒ–ä¸º Markdown åˆ—è¡¨ï¼Œå¼ºåŒ– Prompt çš„æ³¨æ„åŠ›
    lines = ["## å¼ºåˆ¶æœ¯è¯­è¡¨ (Strict Glossary):"]
    for term in data.get("terms", []):
        lines.append(f"- **{term['term']}**: {term['suggested_translation']} ({term['category']})")
    
    # åŠ å…¥ä¸–ç•Œè§‚æ‘˜è¦ï¼Œå¸®åŠ©æ¨¡å‹å®šè°ƒ
    world_info = data.get("world_summary", "")
    return "\n".join(lines) + f"\n\n## ä¸–ç•Œè§‚èƒŒæ™¯:\n{world_info}"

GLOSSARY_CONTEXT = load_glossary_context()

# --- ğŸ”„ å›è¯‘éªŒè¯å‡½æ•° ---
def back_translate(text: str, llm) -> str:
    """
    å°†æ–‡æœ¬å›è¯‘ï¼Œç”¨äºéªŒè¯ç¿»è¯‘è´¨é‡
    
    Args:
        text: è¦å›è¯‘çš„æ–‡æœ¬
        llm: LLMå®ä¾‹
        
    Returns:
        å›è¯‘åçš„æ–‡æœ¬
    """
    back_prompt = ChatPromptTemplate.from_messages([
        ("system", "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç¿»è¯‘ä¸“å®¶ã€‚è¯·å°†ä¸‹é¢çš„è‹±æ–‡æ–‡æœ¬å‡†ç¡®åœ°ç¿»è¯‘å›ä¸­æ–‡ã€‚"),
        ("user", "{text}")
    ])
    
    back_chain = back_prompt | llm | StrOutputParser()
    return back_chain.invoke({"text": text})

# ==============================================================================
# ğŸ­ æ­¥éª¤ 1: åˆç¨¿ç”Ÿæˆ (Drafting)
# ==============================================================================
draft_prompt = ChatPromptTemplate.from_messages([
    ("system", """
    ä½ æ˜¯ä¸€ä½ç²¾é€šä¸­è‹±ç¿»è¯‘çš„å°è¯´å®¶ï¼Œæ“…é•¿â€œç»´å¤šåˆ©äºšå¥‡å¹»â€ä¸â€œå…‹è‹é²ç¥è¯â€é£æ ¼ã€‚
    ä½ çš„ä»»åŠ¡æ˜¯å°†ä¸­æ–‡å°è¯´ã€Šè¯¡ç§˜ä¹‹ä¸»ã€‹ç¿»è¯‘æˆè‹±æ–‡ã€‚
    
    ### é£æ ¼è¦æ±‚ (Style Guide):
    1. **æ°›å›´**: ä¿æŒç¥ç§˜ã€å‹æŠ‘ã€å¤å¤çš„è‹±ä¼¦é£ (Victorian Era)ã€‚
    2. **ç”¨è¯**: ä½¿ç”¨ç‹„æ›´æ–¯æˆ–æŸ¯å—Â·é“å°”å¼çš„è¯æ±‡ï¼ˆä¾‹å¦‚ç”¨ 'Crimson' è€Œé 'Red'ï¼Œç”¨ 'Revolver' è€Œé 'Gun'ï¼‰ã€‚
    3. **å¿ å®**: ä¿ç•™åŸæ–‡çš„å™äº‹èŠ‚å¥å’Œä¼ç¬”ã€‚
    
    {glossary}
    """),
    ("user", "ã€ç« èŠ‚æ ‡é¢˜ã€‘: {title}\n\nã€åŸæ–‡å†…å®¹ã€‘:\n{text}\n\nè¯·ç›´æ¥è¾“å‡ºè‹±æ–‡åˆç¨¿ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šã€‚")
])

# ==============================================================================
# ğŸ§ æ­¥éª¤ 2: å®¡æ ¡ä¸åæ€ (Critique / Self-Reflection)
# ==============================================================================
critique_prompt = ChatPromptTemplate.from_messages([
    ("system", """
    ä½ æ˜¯ä¸€ä½ä¸¥è‹›çš„ç¿»è¯‘å®¡æ ¡ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ£€æŸ¥ä¸€ä»½ã€Šè¯¡ç§˜ä¹‹ä¸»ã€‹çš„è‹±æ–‡è‰ç¨¿ã€‚
    
    è¯·é‡ç‚¹æ£€æŸ¥ä»¥ä¸‹é—®é¢˜ï¼š
    1. **æœ¯è¯­ä¸€è‡´æ€§**: æ˜¯å¦ä¸¥æ ¼éµå®ˆäº†ä»¥ä¸‹æœ¯è¯­è¡¨ï¼Ÿ(ä¾‹å¦‚: 'å€¼å¤œè€…' å¿…é¡»æ˜¯ 'Nighthawks')ã€‚
    2. **æ¼è¯‘/é”™è¯‘**: æ˜¯å¦æœ‰é—æ¼çš„æ®µè½æˆ–æ˜æ˜¾çš„è¯­ä¹‰é”™è¯¯ï¼Ÿ
    3. **é£æ ¼è¿å’Œ**: æ˜¯å¦å‡ºç°äº†è¿‡äºç°ä»£çš„ç¾å¼ä¿šè¯­ï¼ˆå¦‚ 'Okay', 'Cool'ï¼‰ï¼Ÿ
    4. **å›è¯‘éªŒè¯**: å°†è‹±æ–‡è¯‘æ–‡åå‘ç¿»è¯‘å›ä¸­æ–‡ï¼Œä¸åŸæ–‡å¯¹æ¯”ï¼Œæ£€æŸ¥è¯­ä¹‰åå·®ã€‚
    
    {glossary}
    """),
    ("user", "ã€åŸæ–‡ã€‘:\n{original}\n\nã€è‹±æ–‡åˆç¨¿ã€‘:\n{draft}\n\nã€å›è¯‘ä¸­æ–‡ã€‘:\n{back_translation}\n\nè¯·åˆ—å‡ºå…·ä½“çš„ä¿®æ”¹å»ºè®®ï¼ˆå¦‚æœç¿»è¯‘å®Œç¾ï¼Œè¯·ç›´æ¥å›å¤ 'PASS'ï¼‰ã€‚")
])

# ==============================================================================
# âœ¨ æ­¥éª¤ 3: æœ€ç»ˆæ¶¦è‰² (Refinement)
# ==============================================================================
refine_prompt = ChatPromptTemplate.from_messages([
    ("system", """
    ä½ æ˜¯ä¸€ä½è¿½æ±‚å®Œç¾çš„æ–‡å­¦ç¼–è¾‘ã€‚ä½ éœ€è¦æ ¹æ®å®¡æ ¡æ„è§ï¼Œé‡å†™å¹¶æ¶¦è‰²è¯‘æ–‡ã€‚
    
    {glossary}
    """),
    ("user", "ã€åŸæ–‡ã€‘:\n{original}\n\nã€åˆç¨¿ã€‘:\n{draft}\n\nã€å®¡æ ¡æ„è§ã€‘:\n{critique}\n\nè¯·è¾“å‡ºæœ€ç»ˆç‰ˆæœ¬çš„è‹±æ–‡è¯‘æ–‡ã€‚")
])

# --- â›“ï¸ æ„å»º Chain ---
llm_draft = init_llm(temperature=0.3)
llm_critique = init_llm(temperature=0.1)
llm_refine = init_llm(temperature=0.2)
llm_backtranslate = init_llm(temperature=0.0)

draft_chain = draft_prompt | llm_draft | StrOutputParser()
critique_chain = critique_prompt | llm_critique | StrOutputParser()
refine_chain = refine_prompt | llm_refine | StrOutputParser()

# ==============================================================================
# ğŸš€ ä¸»ç¨‹åºï¼šæ‰§è¡Œ TEaR å¾ªç¯
# ==============================================================================
def process_translation():
    """
    æ‰§è¡ŒTEaRç¿»è¯‘å¾ªç¯
    """
    print(f"ğŸ“š è½½å…¥æœ¯è¯­è¡¨ï¼ŒåŒ…å« {GLOSSARY_CONTEXT.count('- **')} ä¸ªæ ¸å¿ƒè¯æ¡ã€‚")
    print("ğŸš€ å¯åŠ¨ TEaR (Translate-Evaluate-Refine) å¼•æ“...\n")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)

    with open(INPUT_FILE, 'r', encoding='utf-8') as fin, \
         open(OUTPUT_FILE, 'w', encoding='utf-8') as fout:
        
        for line in fin:
            chapter = json.loads(line)
            title = chapter['title']
            text = chapter['text']
            
            print(f"â³ [1/4] æ­£åœ¨ç”Ÿæˆåˆç¨¿: {title} ...")
            
            # Step 1: Draft
            draft = draft_chain.invoke({
                "title": title, 
                "text": text, 
                "glossary": GLOSSARY_CONTEXT
            })
            
            print(f"ğŸ”„ [2/4] æ­£åœ¨æ‰§è¡Œå›è¯‘éªŒè¯...")
            # Step 2: Back Translation
            back_translation = back_translate(draft, llm_backtranslate)
            
            print(f"ğŸ§ [3/4] æ­£åœ¨è‡ªæˆ‘å®¡æ ¡...")
            # Step 3: Critique
            critique = critique_chain.invoke({
                "original": text, 
                "draft": draft, 
                "back_translation": back_translation,
                "glossary": GLOSSARY_CONTEXT
            })
            
            final_translation = draft
            
            # åªæœ‰å½“å®¡æ ¡å‘ç°é—®é¢˜æ—¶ï¼Œæ‰æ‰§è¡Œ Refine (èŠ‚çœ Token)
            if "PASS" not in critique and len(critique) > 10:
                print(f"ğŸ”§ [4/4] å‘ç°æ”¹è¿›ç‚¹ï¼Œæ­£åœ¨æ¶¦è‰²...")
                # Step 4: Refine
                final_translation = refine_chain.invoke({
                    "original": text,
                    "draft": draft,
                    "critique": critique,
                    "glossary": GLOSSARY_CONTEXT
                })
            else:
                print(f"âœ… [4/4] åˆç¨¿è´¨é‡å®Œç¾ï¼Œè·³è¿‡æ¶¦è‰²ã€‚")

            # ä¿å­˜ç»“æœï¼ˆåŒ…å«ä¸­é—´è¿‡ç¨‹ï¼Œæ–¹ä¾¿å†™æŠ¥å‘Šå¯¹æ¯”ï¼‰
            result = {
                "chapter_index": chapter['chapter_index'],
                "title": title,
                "draft": draft,
                "back_translation": back_translation,
                "critique": critique,
                "final_translation": final_translation
            }
            
            fout.write(json.dumps(result, ensure_ascii=False) + "\n")
            fout.flush()  # å®æ—¶ä¿å­˜
            
            print("-" * 50)

if __name__ == "__main__":
    process_translation()