# 术语一致性管理系统实现报告

## 设计目标与核心思想

传统翻译系统中的术语表通常是静态列表，无法处理以下问题：
1. **术语类别差异**：命名实体（NE）需要全书唯一，而俚语、领域术语可能在不同语境有不同译法
2. **同词多义**：同一术语在不同上下文需要不同翻译
3. **冲突累积**：不同chunk提取的术语可能产生冲突，需要智能合并或拆分
4. **执行保障**：如何确保翻译阶段真正使用术语表，而非仅作为参考

本系统将"一次性术语列表"升级为"动态一致性管理系统"，通过**结构化存储**、**智能冲突解决**、**双重一致性保障**实现全书术语一致性。

---

## 核心任务完成情况

### 1. 多类别术语提取

**设计思路**：不同类别术语需要不同处理策略。NE（人名、地名、组织名等）必须全书唯一，而domain_term、slang等可能因语境而异。

**实现方式**：
- **修改文件**: `src/3_term_extractor.py`
- **技术方案**: 
  - 使用Pydantic定义`TermExtractionResult`模型，确保LLM输出结构化
  - 通过LangChain的`JsonOutputParser`解析LLM返回的JSON
  - 在system_prompt中明确要求提取7类术语：`NE:person/location/org/deity/language/identity`、`domain_term`、`slang`、`culture_loaded`
- **输出字段**: 
  - `term`: 原文术语
  - `type`: 术语类型（用于后续分层处理）
  - `meaning`: 术语含义/定义
  - `candidates`: 候选翻译列表（至少2-3个）
  - `evidence_span`: 证据片段（用于上下文相似度计算）

**设计逻辑**：结构化输出便于后续处理，evidence_span为冲突解决提供上下文依据。

### 2. 冲突解决与版本化

**设计思路**：当同一术语在不同chunk出现不同翻译时，需要判断是"同一含义不同表达"（合并）还是"不同含义"（拆分sense）。NE术语强制唯一，非NE术语按上下文相似度决策。

**实现方式**：
- **新建文件**: `src/glossary/store.py`（核心模块）
- **冲突解决流程**：
  1. **上下文签名计算**：从`evidence_span`提取关键词（过滤停用词、短词），生成关键词集合的字符串签名
  2. **相似度判断**：使用Jaccard相似度（交集/并集）计算两个上下文的相似度
  3. **决策规则**：
     - **NE术语**：强制唯一译名。若新翻译与现有`final`不一致，保留现有`final`，仅更新`candidates`列表
     - **非NE术语**：
       - 相似度≥0.4：合并，选择最高分候选作为`final`
       - 相似度<0.4：拆分为不同sense（`sense_id`、`context_signature`、`final`、`evidence_span`）
- **版本化机制**：每次保存自动递增版本号，文件名格式`glossary_v{version}.json`，支持历史追溯

**设计逻辑**：阈值0.4基于Jaccard相似度的经验值（通常0.3-0.5为中等相似度），平衡了"过度拆分"和"错误合并"的风险。NE强制唯一符合翻译实践（人名、地名必须一致），非NE允许多义支持语境差异。

### 3. 翻译阶段强制一致性

**设计思路**：仅提供术语表不足以确保使用，需要"主动注入"和"被动检查"双重保障。

**实现方式**：
- **修改文件**: `src/4_translator_tear.py`
- **Glossary Injection（主动保障）**：
  - `get_relevant_terms()`: 根据当前chunk文本检索相关术语（文本匹配+上下文相似度）
  - 对于多义词，选择最匹配的sense（相似度>0.3）
  - `format_for_prompt()`: 将术语映射表格式化为prompt文本，明确要求"必须使用"
- **Post-check（被动保障）**：
  - `check_violations()`: 检查原文中的术语是否在译文中使用了`final`译名
  - 违规分级：`high`（NE术语未使用）、`medium`（非NE术语未使用）、`low`（使用了候选但非final）
  - **自动纠正**：检测到high/medium违规时，触发`CORRECT_TERMS_PROMPT`，使用LLM自动修正译文

**设计逻辑**：Prompt注入让模型"知道"必须使用，Post-check验证"是否使用"，自动纠正确保"最终使用"，形成闭环。

### 4. 多义词处理

**设计思路**：同一术语在不同语境可能有不同含义，需要根据当前文本上下文选择正确的义项。

**实现方式**：
- **Sense拆分**：冲突解决时，若上下文相似度<0.4，创建sense分支
- **Sense选择**：翻译时，计算当前文本与各sense的`context_signature`相似度
  - 相似度>0.3：使用该sense的`final`
  - 相似度≤0.3：使用主entry的`final`
- **集成位置**：`get_relevant_terms()`和`check_violations()`均考虑sense选择

**设计逻辑**：阈值0.3低于冲突判断的0.4，因为翻译时只需"找到最接近的sense"而非"严格匹配"，允许一定容错。

---

## 运行结果分析（Run ID: 20260108_202510_0fdc6d）

**运行概况**: 前10章，耗时6235秒（约104分钟），处理10个chunk，生成33个术语条目，所有chunk的violations检查均通过。请参考test_results_demo文件夹。

**结果验证**:
- **术语表质量**（`glossary_v1.json`）:
  - 33个结构化术语条目，类型分布：NE:person 8个，NE:location 4个，NE:org 4个，NE:deity 3个，NE:language 2个，NE:identity 3个，domain_term 6个
  - 所有条目包含完整字段：`type`、`final`、`candidates`（带score和source）、`evidence_span`、`senses`（当前为空，因未出现冲突）
  - 版本号字段正常（version=1）
- **一致性检查**（`chunks/*/chunk_id.json`）:
  - 10个chunk的`violations`字段均为空或仅包含"needs_refine"（非术语违规）
  - 说明Glossary Injection机制有效，模型成功遵循了术语表要求
- **翻译质量**（`final/book_merged_zh.txt`）:
  - 术语翻译全书一致，如"Klein Moretti"（克莱恩・莫雷蒂）、"Tingen City"（廷根市）、"Khoy University"（霍伊大学）等在全文中保持一致
  - 未发现术语混用或错误翻译

**结论**: 系统成功实现了从"一次性术语列表"到"动态一致性管理系统"的转变，解决了术语类别区分、多义词处理、冲突解决和翻译阶段强制执行等核心问题。

---

## 技术实现

### 使用的开源工具

1. **LangChain/LangGraph**: 
   - 用于构建多Agent工作流，实现TEaR（Translate-Evaluate-Refine）循环
   - `ChatPromptTemplate`: 管理prompt模板，支持变量注入
   - `JsonOutputParser`: 解析LLM的结构化JSON输出，配合Pydantic模型使用

2. **Pydantic**: 
   - 定义`TermExtractionResult`和`TermExtractionOutput`数据模型
   - 确保LLM输出的类型安全和结构一致性，避免解析错误

3. **LangChain OpenAI**: 
   - 通过`ChatOpenAI`封装LLM调用，支持多种模型
   - 本运行使用DeepSeek-R1模型

### 核心修改点

1. **`src/3_term_extractor.py`**:
   - 新增Pydantic模型定义（`TermExtractionResult`、`TermExtractionOutput`）
   - 重构system_prompt，明确要求7种类型术语，提供示例
   - 集成`JsonOutputParser`，将LLM输出解析为结构化数据

2. **`src/glossary/store.py`**（新建，核心模块）:
   - 实现`GlossaryStore`类，管理术语表的加载、保存、冲突解决
   - 关键词提取（`_extract_keywords`）：过滤停用词，提取关键词
   - 上下文签名计算（`_compute_context_signature`）：生成可比较的字符串签名
   - 相似度判断（`_are_contexts_similar`）：Jaccard相似度计算
   - 冲突解决（`_resolve_conflict`）：分层策略（NE强制唯一，非NE按相似度）
   - Sense拆分（`_split_into_senses_keyword`）：创建sense分支
   - Sense选择（`get_relevant_terms`）：翻译时选择最匹配的sense
   - 违规检查（`check_violations`）：检查术语使用一致性

3. **`src/4_translator_tear.py`**:
   - 修改`_format_glossary()`：支持上下文相关的术语检索（调用`get_relevant_terms()`）
   - 新增术语违规检查与自动纠正：在翻译和refine后检查violations，触发自动修正

4. **`src/workflow/graph.py`**:
   - 集成`GlossaryStore`到工作流的`load_or_extract_glossary_node`
   - 实现类型规范化（`_normalize_glossary`）：将旧格式类型（如"Person"）转换为标准格式（"NE:person"）











## 创新点

1. **分层冲突解决**: NE强制唯一，非NE允许多义，符合翻译实践
2. **轻量级相似度**: 基于关键词Jaccard，无需embedding，计算高效
3. **双重保障机制**: Prompt注入+Post-check，确保术语正确使用
4. **版本化存储**: 自动版本递增，支持历史追溯
5. **动态sense选择**: 翻译时根据上下文选择正确义项

---

## 技术难点

1. **相似度阈值设定**:
   - **问题**：阈值过高会导致错误合并（不同含义被合并），过低会导致过度拆分（相同含义被拆分）
   - **解决方案**：设置为0.4，基于Jaccard相似度的经验值（通常0.3-0.5为中等相似度范围）
   - **权衡**：0.4在"避免错误合并"和"避免过度拆分"之间取得平衡
   - **Sense选择阈值**：使用0.3（低于冲突判断），因为翻译时只需"找到最接近的sense"，允许一定容错

2. **NE术语唯一性强制**:
   - **问题**：NE术语（人名、地名）必须全书一致，但冲突解决逻辑可能因上下文差异而拆分
   - **解决方案**：在`_resolve_conflict()`中首先判断术语类型，NE类型直接强制唯一，不进行相似度判断
   - **实现细节**：若新翻译与现有final不一致，保留现有final，仅将新翻译加入candidates列表（score=0.5，source="conflict"）

3. **Violations检查的准确性**:
   - **问题**：需要处理术语在原文中的变体（大小写、标点、词形变化）以及译文中的同义词使用
   - **解决方案**：
     - 原文匹配：使用`term in text`和`term.lower() in text_lower`进行大小写不敏感匹配
     - 译文检查：在译文中搜索final译名，支持部分匹配（避免因标点、大小写导致误判）
     - 分级处理：high（NE术语，必须严格）、medium（非NE术语，允许一定容错）、low（使用候选但非final，仅记录）

4. **Sense选择与Violations检查的协调**:
   - **问题**：翻译时选择了某个sense的final，但violations检查时需要知道选择了哪个sense
   - **解决方案**：
     - 在`get_relevant_terms()`中，若选择了sense，在返回的entry中添加`_selected_sense`字段
     - 在`check_violations()`中，检查`_selected_sense`字段，若存在则使用sense的final进行验证
   - **设计逻辑**：确保翻译时选择的sense与检查时使用的sense一致，避免误报

---

## 方法优势

相比传统一次性术语列表方法，本系统实现了以下改进：

1. **动态管理**:
   - 传统方法：静态列表，无法处理新增术语和冲突
   - 本系统：术语表随翻译进程动态更新，支持增量添加和自动冲突解决
   - **优势**：适应长文本翻译场景，无需预先准备完整术语表

2. **智能合并**:
   - 传统方法：人工判断是否合并，容易出错
   - 本系统：基于上下文相似度自动决策，相似度高则合并，差异大则拆分
   - **优势**：减少人工干预，提高效率，避免主观判断偏差

3. **强制一致性**:
   - 传统方法：仅提供术语表，模型可能忽略或误用
   - 本系统：Prompt注入（主动）+ Post-check（被动）+ 自动纠正（闭环）
   - **优势**：确保术语真正被使用，而非仅作为参考

4. **可追溯性**:
   - 传统方法：无法追溯术语变更历史
   - 本系统：版本化存储（`glossary_v{version}.json`），每次更新自动递增版本号
   - **优势**：支持历史查询、问题定位和版本回滚

5. **可扩展性**:
   - 传统方法：不支持多义词处理
   - 本系统：支持sense拆分和动态选择，预留LLM消歧接口（`_split_into_senses_llm`）
   - **优势**：适应复杂翻译场景，为未来增强预留空间

---

## 参考文献

1. Translation Memory系统设计（SDL Trados, MemoQ等）
2. Word Sense Disambiguation经典方法（Lesk算法、上下文窗口）
3. LangGraph官方文档（工作流构建与状态管理）
4. LangChain Prompt Engineering最佳实践
5. Pydantic文档（数据验证与LLM集成模式）